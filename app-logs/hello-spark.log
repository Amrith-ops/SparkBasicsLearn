24/09/22 22:20:28 INFO HelloSpark$: Starting Hello spark
24/09/22 22:20:29 INFO SparkContext: Running Spark version 3.0.0-preview2
24/09/22 22:20:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/09/22 22:20:29 INFO ResourceUtils: ==============================================================
24/09/22 22:20:29 INFO ResourceUtils: Resources for spark.driver:

24/09/22 22:20:29 INFO ResourceUtils: ==============================================================
24/09/22 22:20:29 INFO SparkContext: Submitted application: Hello Spark
24/09/22 22:20:29 INFO SecurityManager: Changing view acls to: amrit
24/09/22 22:20:29 INFO SecurityManager: Changing modify acls to: amrit
24/09/22 22:20:29 INFO SecurityManager: Changing view acls groups to: 
24/09/22 22:20:29 INFO SecurityManager: Changing modify acls groups to: 
24/09/22 22:20:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(amrit); groups with view permissions: Set(); users  with modify permissions: Set(amrit); groups with modify permissions: Set()
24/09/22 22:20:31 INFO Utils: Successfully started service 'sparkDriver' on port 51678.
24/09/22 22:20:31 INFO SparkEnv: Registering MapOutputTracker
24/09/22 22:20:31 INFO SparkEnv: Registering BlockManagerMaster
24/09/22 22:20:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/09/22 22:20:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/09/22 22:20:31 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/09/22 22:20:31 INFO DiskBlockManager: Created local directory at C:\Users\amrit\AppData\Local\Temp\blockmgr-4db33ad5-bae9-43ef-b0e1-d03b4ada9443
24/09/22 22:20:31 INFO MemoryStore: MemoryStore started with capacity 1023.6 MiB
24/09/22 22:20:31 INFO SparkEnv: Registering OutputCommitCoordinator
24/09/22 22:20:31 INFO log: Logging initialized @4878ms to org.sparkproject.jetty.util.log.Slf4jLog
24/09/22 22:20:31 INFO Server: jetty-9.4.z-SNAPSHOT; built: 2019-04-29T20:42:08.989Z; git: e1bc35120a6617ee3df052294e433f3a25ce7097; jvm 11.0.13+10-LTS-370
24/09/22 22:20:31 INFO Server: Started @5002ms
24/09/22 22:20:31 INFO AbstractConnector: Started ServerConnector@7275c74b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
24/09/22 22:20:31 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/09/22 22:20:31 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5acc9fdf{/jobs,null,AVAILABLE,@Spark}
24/09/22 22:20:31 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1bf39d06{/jobs/json,null,AVAILABLE,@Spark}
24/09/22 22:20:31 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1ac45389{/jobs/job,null,AVAILABLE,@Spark}
24/09/22 22:20:31 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@62891fc8{/jobs/job/json,null,AVAILABLE,@Spark}
24/09/22 22:20:31 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@fca387{/stages,null,AVAILABLE,@Spark}
24/09/22 22:20:31 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3ae0b770{/stages/json,null,AVAILABLE,@Spark}
24/09/22 22:20:31 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@30e6a763{/stages/stage,null,AVAILABLE,@Spark}
24/09/22 22:20:31 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@213c3543{/stages/stage/json,null,AVAILABLE,@Spark}
24/09/22 22:20:31 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@670ce331{/stages/pool,null,AVAILABLE,@Spark}
24/09/22 22:20:31 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@7c29adc8{/stages/pool/json,null,AVAILABLE,@Spark}
24/09/22 22:20:31 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4bbb49b0{/storage,null,AVAILABLE,@Spark}
24/09/22 22:20:31 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3effd4f3{/storage/json,null,AVAILABLE,@Spark}
24/09/22 22:20:31 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@15f8701f{/storage/rdd,null,AVAILABLE,@Spark}
24/09/22 22:20:31 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@11d4dbd6{/storage/rdd/json,null,AVAILABLE,@Spark}
24/09/22 22:20:31 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@39e43310{/environment,null,AVAILABLE,@Spark}
24/09/22 22:20:31 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@390877d2{/environment/json,null,AVAILABLE,@Spark}
24/09/22 22:20:31 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@186cb891{/executors,null,AVAILABLE,@Spark}
24/09/22 22:20:31 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@440eaa07{/executors/json,null,AVAILABLE,@Spark}
24/09/22 22:20:31 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@7aa9e414{/executors/threadDump,null,AVAILABLE,@Spark}
24/09/22 22:20:31 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@624a24f6{/executors/threadDump/json,null,AVAILABLE,@Spark}
24/09/22 22:20:31 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@338cc75f{/static,null,AVAILABLE,@Spark}
24/09/22 22:20:31 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@31edeac{/,null,AVAILABLE,@Spark}
24/09/22 22:20:31 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@45bb2aa1{/api,null,AVAILABLE,@Spark}
24/09/22 22:20:31 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6d469831{/jobs/job/kill,null,AVAILABLE,@Spark}
24/09/22 22:20:31 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@2ff15f8c{/stages/stage/kill,null,AVAILABLE,@Spark}
24/09/22 22:20:31 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.56.1:4040
24/09/22 22:20:32 INFO Executor: Starting executor ID driver on host 192.168.56.1
24/09/22 22:20:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51705.
24/09/22 22:20:32 INFO NettyBlockTransferService: Server created on 192.168.56.1:51705
24/09/22 22:20:32 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/09/22 22:20:32 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.56.1, 51705, None)
24/09/22 22:20:32 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.56.1:51705 with 1023.6 MiB RAM, BlockManagerId(driver, 192.168.56.1, 51705, None)
24/09/22 22:20:32 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.56.1, 51705, None)
24/09/22 22:20:32 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.56.1, 51705, None)
24/09/22 22:20:32 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@28bdbe88{/metrics/json,null,AVAILABLE,@Spark}
24/09/22 22:20:32 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/amrit/IdeaProjects/SparkBasicsLearn/spark-warehouse').
24/09/22 22:20:32 INFO SharedState: Warehouse path is 'file:/C:/Users/amrit/IdeaProjects/SparkBasicsLearn/spark-warehouse'.
24/09/22 22:20:32 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6b6eae52{/SQL,null,AVAILABLE,@Spark}
24/09/22 22:20:32 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@7ae0cc89{/SQL/json,null,AVAILABLE,@Spark}
24/09/22 22:20:32 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@7bcecef6{/SQL/execution,null,AVAILABLE,@Spark}
24/09/22 22:20:32 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@93824eb{/SQL/execution/json,null,AVAILABLE,@Spark}
24/09/22 22:20:32 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@659f226a{/static/sql,null,AVAILABLE,@Spark}
24/09/22 22:20:36 INFO FileSourceStrategy: Pruning directories with: 
24/09/22 22:20:36 INFO FileSourceStrategy: Pushed Filters: 
24/09/22 22:20:36 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
24/09/22 22:20:36 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
24/09/22 22:20:36 INFO CodeGenerator: Code generated in 291.0587 ms
24/09/22 22:20:36 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 170.9 KiB, free 1023.4 MiB)
24/09/22 22:20:37 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.9 KiB, free 1023.4 MiB)
24/09/22 22:20:37 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.56.1:51705 (size: 23.9 KiB, free: 1023.6 MiB)
24/09/22 22:20:37 INFO SparkContext: Created broadcast 0 from csv at HelloSpark.scala:51
24/09/22 22:20:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
24/09/22 22:20:37 INFO SparkContext: Starting job: csv at HelloSpark.scala:51
24/09/22 22:20:37 INFO DAGScheduler: Got job 0 (csv at HelloSpark.scala:51) with 1 output partitions
24/09/22 22:20:37 INFO DAGScheduler: Final stage: ResultStage 0 (csv at HelloSpark.scala:51)
24/09/22 22:20:37 INFO DAGScheduler: Parents of final stage: List()
24/09/22 22:20:37 INFO DAGScheduler: Missing parents: List()
24/09/22 22:20:37 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at HelloSpark.scala:51), which has no missing parents
24/09/22 22:20:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.7 KiB, free 1023.4 MiB)
24/09/22 22:20:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 1023.4 MiB)
24/09/22 22:20:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.56.1:51705 (size: 5.3 KiB, free: 1023.6 MiB)
24/09/22 22:20:37 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1206
24/09/22 22:20:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at HelloSpark.scala:51) (first 15 tasks are for partitions Vector(0))
24/09/22 22:20:37 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
24/09/22 22:20:37 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.56.1, executor driver, partition 0, PROCESS_LOCAL, 7765 bytes)
24/09/22 22:20:37 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/09/22 22:20:37 INFO FileScanRDD: Reading File path: file:///C:/Users/amrit/IdeaProjects/SparkBasicsLearn/data/sample.csv, range: 0-2214, partition values: [empty row]
24/09/22 22:20:37 INFO CodeGenerator: Code generated in 16.5904 ms
24/09/22 22:20:37 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1929 bytes result sent to driver
24/09/22 22:20:37 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 460 ms on 192.168.56.1 (executor driver) (1/1)
24/09/22 22:20:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/09/22 22:20:37 INFO DAGScheduler: ResultStage 0 (csv at HelloSpark.scala:51) finished in 0.603 s
24/09/22 22:20:37 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/22 22:20:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/09/22 22:20:37 INFO DAGScheduler: Job 0 finished: csv at HelloSpark.scala:51, took 0.652306 s
24/09/22 22:20:37 INFO CodeGenerator: Code generated in 15.7099 ms
24/09/22 22:20:37 INFO FileSourceStrategy: Pruning directories with: 
24/09/22 22:20:37 INFO FileSourceStrategy: Pushed Filters: 
24/09/22 22:20:37 INFO FileSourceStrategy: Post-Scan Filters: 
24/09/22 22:20:37 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
24/09/22 22:20:37 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 170.9 KiB, free 1023.2 MiB)
24/09/22 22:20:38 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.9 KiB, free 1023.2 MiB)
24/09/22 22:20:38 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.56.1:51705 (size: 23.9 KiB, free: 1023.5 MiB)
24/09/22 22:20:38 INFO SparkContext: Created broadcast 2 from csv at HelloSpark.scala:51
24/09/22 22:20:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
24/09/22 22:20:38 INFO SparkContext: Starting job: csv at HelloSpark.scala:51
24/09/22 22:20:38 INFO DAGScheduler: Got job 1 (csv at HelloSpark.scala:51) with 1 output partitions
24/09/22 22:20:38 INFO DAGScheduler: Final stage: ResultStage 1 (csv at HelloSpark.scala:51)
24/09/22 22:20:38 INFO DAGScheduler: Parents of final stage: List()
24/09/22 22:20:38 INFO DAGScheduler: Missing parents: List()
24/09/22 22:20:38 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at HelloSpark.scala:51), which has no missing parents
24/09/22 22:20:38 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 192.168.56.1:51705 in memory (size: 23.9 KiB, free: 1023.6 MiB)
24/09/22 22:20:38 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.56.1:51705 in memory (size: 5.3 KiB, free: 1023.6 MiB)
24/09/22 22:20:38 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 14.9 KiB, free 1023.4 MiB)
24/09/22 22:20:38 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 1023.4 MiB)
24/09/22 22:20:38 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.56.1:51705 (size: 7.4 KiB, free: 1023.6 MiB)
24/09/22 22:20:38 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1206
24/09/22 22:20:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at HelloSpark.scala:51) (first 15 tasks are for partitions Vector(0))
24/09/22 22:20:38 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
24/09/22 22:20:38 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 192.168.56.1, executor driver, partition 0, PROCESS_LOCAL, 7765 bytes)
24/09/22 22:20:38 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
24/09/22 22:20:38 INFO FileScanRDD: Reading File path: file:///C:/Users/amrit/IdeaProjects/SparkBasicsLearn/data/sample.csv, range: 0-2214, partition values: [empty row]
24/09/22 22:20:38 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1930 bytes result sent to driver
24/09/22 22:20:38 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 90 ms on 192.168.56.1 (executor driver) (1/1)
24/09/22 22:20:38 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/09/22 22:20:38 INFO DAGScheduler: ResultStage 1 (csv at HelloSpark.scala:51) finished in 0.221 s
24/09/22 22:20:38 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/22 22:20:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
24/09/22 22:20:38 INFO DAGScheduler: Job 1 finished: csv at HelloSpark.scala:51, took 0.234871 s
24/09/22 22:20:38 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
24/09/22 22:20:38 INFO V2ScanRelationPushDown: 
Pushing operators to csv file:/C:/Users/amrit/IdeaProjects/SparkBasicsLearn/data/sample.csv
Pushed Filters: 
Post-Scan Filters: isnotnull(Age#15),(Age#15 < 40)
Output: Age#15, Country#17
         
24/09/22 22:20:38 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.56.1:51705 in memory (size: 7.4 KiB, free: 1023.6 MiB)
24/09/22 22:20:38 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 170.9 KiB, free 1023.2 MiB)
24/09/22 22:20:38 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.56.1:51705 in memory (size: 23.9 KiB, free: 1023.6 MiB)
24/09/22 22:20:38 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 23.9 KiB, free 1023.4 MiB)
24/09/22 22:20:38 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.56.1:51705 (size: 23.9 KiB, free: 1023.6 MiB)
24/09/22 22:20:38 INFO SparkContext: Created broadcast 4 from collect at HelloSpark.scala:37
24/09/22 22:20:39 INFO CodeGenerator: Code generated in 82.5958 ms
24/09/22 22:20:39 INFO CodeGenerator: Code generated in 160.5282 ms
24/09/22 22:20:39 INFO CodeGenerator: Code generated in 19.4778 ms
24/09/22 22:20:39 INFO SparkContext: Starting job: collect at HelloSpark.scala:37
24/09/22 22:20:39 INFO DAGScheduler: Registering RDD 14 (collect at HelloSpark.scala:37) as input to shuffle 0
24/09/22 22:20:39 INFO DAGScheduler: Registering RDD 17 (collect at HelloSpark.scala:37) as input to shuffle 1
24/09/22 22:20:39 INFO DAGScheduler: Got job 2 (collect at HelloSpark.scala:37) with 2 output partitions
24/09/22 22:20:39 INFO DAGScheduler: Final stage: ResultStage 4 (collect at HelloSpark.scala:37)
24/09/22 22:20:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
24/09/22 22:20:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
24/09/22 22:20:39 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[14] at collect at HelloSpark.scala:37), which has no missing parents
24/09/22 22:20:39 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 15.5 KiB, free 1023.4 MiB)
24/09/22 22:20:39 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 1023.4 MiB)
24/09/22 22:20:39 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.56.1:51705 (size: 7.8 KiB, free: 1023.6 MiB)
24/09/22 22:20:39 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1206
24/09/22 22:20:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[14] at collect at HelloSpark.scala:37) (first 15 tasks are for partitions Vector(0))
24/09/22 22:20:39 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
24/09/22 22:20:39 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, 192.168.56.1, executor driver, partition 0, PROCESS_LOCAL, 7923 bytes)
24/09/22 22:20:39 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
24/09/22 22:20:39 INFO CodeGenerator: Code generated in 15.8242 ms
24/09/22 22:20:39 INFO FilePartitionReader: Reading file path: file:///C:/Users/amrit/IdeaProjects/SparkBasicsLearn/data/sample.csv, range: 0-2214, partition values: [empty row]
24/09/22 22:20:40 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2046 bytes result sent to driver
24/09/22 22:20:40 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 403 ms on 192.168.56.1 (executor driver) (1/1)
24/09/22 22:20:40 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/09/22 22:20:40 INFO DAGScheduler: ShuffleMapStage 2 (collect at HelloSpark.scala:37) finished in 0.479 s
24/09/22 22:20:40 INFO DAGScheduler: looking for newly runnable stages
24/09/22 22:20:40 INFO DAGScheduler: running: Set()
24/09/22 22:20:40 INFO DAGScheduler: waiting: Set(ShuffleMapStage 3, ResultStage 4)
24/09/22 22:20:40 INFO DAGScheduler: failed: Set()
24/09/22 22:20:40 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[17] at collect at HelloSpark.scala:37), which has no missing parents
24/09/22 22:20:40 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 30.0 KiB, free 1023.4 MiB)
24/09/22 22:20:40 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 14.0 KiB, free 1023.3 MiB)
24/09/22 22:20:40 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.56.1:51705 (size: 14.0 KiB, free: 1023.6 MiB)
24/09/22 22:20:40 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1206
24/09/22 22:20:40 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[17] at collect at HelloSpark.scala:37) (first 15 tasks are for partitions Vector(0, 1))
24/09/22 22:20:40 INFO TaskSchedulerImpl: Adding task set 3.0 with 2 tasks
24/09/22 22:20:40 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, 192.168.56.1, executor driver, partition 0, NODE_LOCAL, 7237 bytes)
24/09/22 22:20:40 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 4, 192.168.56.1, executor driver, partition 1, NODE_LOCAL, 7237 bytes)
24/09/22 22:20:40 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
24/09/22 22:20:40 INFO Executor: Running task 1.0 in stage 3.0 (TID 4)
24/09/22 22:20:40 INFO ShuffleBlockFetcherIterator: Getting 1 (129.0 B) non-empty blocks including 1 (129.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
24/09/22 22:20:40 INFO ShuffleBlockFetcherIterator: Getting 1 (106.0 B) non-empty blocks including 1 (106.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
24/09/22 22:20:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
24/09/22 22:20:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
24/09/22 22:20:40 INFO CodeGenerator: Code generated in 15.9649 ms
24/09/22 22:20:40 INFO CodeGenerator: Code generated in 9.9751 ms
24/09/22 22:20:40 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.56.1:51705 in memory (size: 7.8 KiB, free: 1023.6 MiB)
24/09/22 22:20:40 INFO CodeGenerator: Code generated in 15.6525 ms
24/09/22 22:20:40 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 4205 bytes result sent to driver
24/09/22 22:20:40 INFO Executor: Finished task 1.0 in stage 3.0 (TID 4). 4205 bytes result sent to driver
24/09/22 22:20:40 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 251 ms on 192.168.56.1 (executor driver) (1/2)
24/09/22 22:20:40 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 4) in 248 ms on 192.168.56.1 (executor driver) (2/2)
24/09/22 22:20:40 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
24/09/22 22:20:40 INFO DAGScheduler: ShuffleMapStage 3 (collect at HelloSpark.scala:37) finished in 0.276 s
24/09/22 22:20:40 INFO DAGScheduler: looking for newly runnable stages
24/09/22 22:20:40 INFO DAGScheduler: running: Set()
24/09/22 22:20:40 INFO DAGScheduler: waiting: Set(ResultStage 4)
24/09/22 22:20:40 INFO DAGScheduler: failed: Set()
24/09/22 22:20:40 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[20] at collect at HelloSpark.scala:37), which has no missing parents
24/09/22 22:20:40 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 28.7 KiB, free 1023.3 MiB)
24/09/22 22:20:40 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 13.1 KiB, free 1023.3 MiB)
24/09/22 22:20:40 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.56.1:51705 (size: 13.1 KiB, free: 1023.6 MiB)
24/09/22 22:20:40 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1206
24/09/22 22:20:40 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[20] at collect at HelloSpark.scala:37) (first 15 tasks are for partitions Vector(0, 1))
24/09/22 22:20:40 INFO TaskSchedulerImpl: Adding task set 4.0 with 2 tasks
24/09/22 22:20:40 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 5, 192.168.56.1, executor driver, partition 1, NODE_LOCAL, 7248 bytes)
24/09/22 22:20:40 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, 192.168.56.1, executor driver, partition 0, PROCESS_LOCAL, 7248 bytes)
24/09/22 22:20:40 INFO Executor: Running task 0.0 in stage 4.0 (TID 6)
24/09/22 22:20:40 INFO Executor: Running task 1.0 in stage 4.0 (TID 5)
24/09/22 22:20:40 INFO ShuffleBlockFetcherIterator: Getting 0 (0.0 B) non-empty blocks including 0 (0.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
24/09/22 22:20:40 INFO ShuffleBlockFetcherIterator: Getting 2 (235.0 B) non-empty blocks including 2 (235.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
24/09/22 22:20:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
24/09/22 22:20:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
24/09/22 22:20:40 INFO Executor: Finished task 0.0 in stage 4.0 (TID 6). 5543 bytes result sent to driver
24/09/22 22:20:40 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 43 ms on 192.168.56.1 (executor driver) (1/2)
24/09/22 22:20:40 INFO Executor: Finished task 1.0 in stage 4.0 (TID 5). 5716 bytes result sent to driver
24/09/22 22:20:40 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 5) in 74 ms on 192.168.56.1 (executor driver) (2/2)
24/09/22 22:20:40 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
24/09/22 22:20:40 INFO DAGScheduler: ResultStage 4 (collect at HelloSpark.scala:37) finished in 0.102 s
24/09/22 22:20:40 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/09/22 22:20:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
24/09/22 22:20:40 INFO DAGScheduler: Job 2 finished: collect at HelloSpark.scala:37, took 0.912478 s
24/09/22 22:20:40 INFO CodeGenerator: Code generated in 17.2076 ms
24/09/22 22:20:40 INFO HelloSpark$: [United Kingdom,1]->[Canada,2]->[United States,4]
24/09/22 22:20:40 INFO HelloSpark$: Ending Hello spark
24/09/22 22:20:47 WARN ProcfsMetricsGetter: Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
